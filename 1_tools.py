# %%\nimport os\n\nimport openai\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclient = openai.OpenAI(\n    api_key=os.environ.get("OPENAI_API_KEY"),\n)\n\nPROMPT = (\n    "find 201122 removed from 316043 and then find the square root of the result. "\n    "Return this value **only** with no other words."\n)\n\n# This time, we give the LLM some tools it can use as it\'s finding the answer\ndef subtract(a: int, b: int) -> int:\n    return a-b\n\ndef sqrt(num: int) -> float:\n    return num**0.5\n\nTOOL_MAPPING = {\n    "subtract": subtract,\n    "sqrt": sqrt,\n}\n\nTOOLS = [\n    {\n        "type": "function",\n        "function": {\n            "name": "subtract",\n            "description": "Calculate the difference between `a` and `b`",\n            "parameters": {\n                "type": "object",\n                "properties": {\n                    "a": {\n                        "type": "number",\n                        "description": "The first operand",\n                    },\n                    "b": {\n                        "type": "number",\n                        "description": "The second operand; the number to be subracted",\n                    }\n                },\n                "required": ["a", "b"],\n            },\
        }\n    },\n    {\n        "type": "function",\n        "function": {\n            "name": "sqrt",\n            "description": "Find the square root of an integer",\n            "parameters": {\n                "type": "object",\n                "properties": {\n                    "num": {\n                        "type": "number",\n                        "description": "The operand to find the square root of",\n                    },\n                },\n                "required": ["num"],\n            },\
        }\n    }\n]\n\n# %%\ninitial_response = client.chat.completions.create(\n    model="gpt-4o-mini",\n    max_tokens=1024,\n    tools=TOOLS,\n    messages=[{"role": "user", "content": PROMPT}],\n)\n\nprint(\'Initial response:\')\nprint(initial_response)\nprint(initial_response.choices[0].message)\n\n# %%\nif initial_response.choices[0].message.tool_calls:\n    tool_call = initial_response.choices[0].message.tool_calls[0]\n    tool_name = tool_call.function.name\n    tool_args = eval(tool_call.function.arguments)\n    \n    tool_result = TOOL_MAPPING[tool_name](**tool_args)\n    \n    tool_reply = {\n        "role": "user",\n        "content": None,\n        "tool_call_id": tool_call.id,\n        "name": tool_name,\n        "tool_calls": [tool_call]\n    }\n    \n    intermediate_response = client.chat.completions.create(\n        model="gpt-4o-mini",\n        max_tokens=1024,\n        tools=TOOLS,\n        messages=[\n            {"role": "user", "content": PROMPT},\n            {"role": "assistant", "content": None, "tool_calls": [tool_call]},\n            {"role": "tool", "tool_call_id": tool_call.id, "name": tool_name, "content": str(tool_result)}\n        ],\n    )\n    \n    print(\'Intermediate response:\')\n    print(intermediate_response)\n    print(intermediate_response.choices[0].message)\n    \n    if intermediate_response.choices[0].message.tool_calls:\n        tool_call = intermediate_response.choices[0].message.tool_calls[0]\n        tool_name = tool_call.function.name\n        tool_args = eval(tool_call.function.arguments)\n        \n        tool_result = TOOL_MAPPING[tool_name](**tool_args)\n        \n        final_response = client.chat.completions.create(\n            model="gpt-4o-mini",\n            max_tokens=1024,\n            tools=TOOLS,\n            messages=[\n                {"role": "user", "content": PROMPT},\n                {"role": "assistant", "content": None, "tool_calls": [tool_call]},\n                {"role": "tool", "tool_call_id": tool_call.id, "name": tool_name, "content": str(tool_result)}\n            ],\n        )\n        \n        print(\'Final response:\')\n        print(final_response)\n        print(final_response.choices[0].message)\n        print(final_response.choices[0].message.content)\n\n# %%\n